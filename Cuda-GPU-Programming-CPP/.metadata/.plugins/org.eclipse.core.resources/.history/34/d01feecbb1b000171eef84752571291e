/* Simple GPU executable code for Vector Addition
 * GPU-CODE
 * Author : Janvijay Singh
 */

#include<bits/stdc++.h>
#include <cuda_runtime.h>

#define SIZE 1024

using namespace std;

// Function to be executed on GPU and will be called from the Host
// Function to be run by many threads in parallel
// To identify each thread use read-only variable threadIdx.x
__global__ void VectorAdd(int *a, int *b, int *c, int n)
{
	int i=threadIdx.x;

	// To check if current thread Id is less than number of elements in array
	// To overcome any issues which might occur if number of threads launched turn
	// out to be grater than number of elements in array
	if(i<n)
		c[i] = a[i] + b[i];
}

int main()
{
	int *a, *b, *c;

	// Memory Allocation in Unified space accessible from CPU as well as GPU
	cudaMallocManaged(&a, SIZE * sizeof(int));
	cudaMallocManaged(&b, SIZE * sizeof(int));
	cudaMallocManaged(&c, SIZE * sizeof(int));

	// Initialization
	for(int i=0;i<SIZE;i++)
	{
		a[i] = i;
		b[i] = i;
		c[i] = 0;
	}

	// Specifies launch configuration of the kernel
	// Triple Able brackets :
	// First Parameter  : No. of thread blocks
	// Second Parameter : No. of threads in each thread block
	VectorAdd <<<1, SIZE>>> (a, b, c, SIZE);

	cudaDeviceSynchronize();

	// Printing out first 10 elements of output vector
	for(int i=0;i<10; ++i)
		printf("c[%d] = %d\n", i, c[i]);

	// Freeing memory
	cudaFree(a);
	cudaFree(b);
	cudaFree(c);

	return 0;
}
